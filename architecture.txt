Thread 1: A2C
* Gets passed the segments list and the reward predictor.
* Appends segments to the segment list.
* Only accesses reward prediction in the reward predictor.

Thread 2: reward predictor training
* Gets passed the segments list and the preference database.
* Just loops through the preference database.

Thread 3: preference interface
* Has access to the segments, the preference database, and the reward predictor
* Selects 10 segments, and checks them using the reward predictor.
* Selects the highest-variance segment and shows it to the user.
* Appends the choice to the preference database.


# Saved parameters

`load` gets passed to:
* a2c `learn`, where it doesn't do anything
* `train_reward_predictor`, where it:
  * is passed to the init function, where it loads a checkpoint
  * reward_model.train, where it loads preferences and segments
